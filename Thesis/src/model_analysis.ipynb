{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explainability of models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From https://pytorch-geometric.readthedocs.io/en/latest/tutorial/explain.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load model\n",
    "...\n",
    "\n",
    "#load data\n",
    "..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run below on homogenous graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "from torch_geometric.explain import Explainer, GNNExplainer\n",
    "\n",
    "data = Data(...)  # A homogeneous graph data object.\n",
    "\n",
    "explainer = Explainer(\n",
    "    model=model,\n",
    "    algorithm=GNNExplainer(epochs=200),\n",
    "    explanation_type='model',\n",
    "    node_mask_type='attributes',\n",
    "    edge_mask_type='object',\n",
    "    model_config=dict(\n",
    "        mode='multiclass_classification',\n",
    "        task_level='node',\n",
    "        return_type='log_probs',  # Model returns log probabilities.\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Generate explanation for the node at index `10`:\n",
    "explanation = explainer(data.x, data.edge_index, index=10)\n",
    "print(explanation.edge_mask)\n",
    "print(explanation.node_mask)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize feature importance and crucial subgraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation.visualize_feature_importance(top_k=10)\n",
    "explanation.visualize_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.explain import unfaithfulness\n",
    "\n",
    "metric = unfaithfulness(explainer, explanation)\n",
    "print(metric)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our graph however is heterogenous - multiple different types of nodes\n",
    "\n",
    "but we don't predict different node classes and we don't do conv on the other node types\n",
    "\n",
    "So for cell conv alone, we could probably get by with homogenous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for each output of MLP which inputs plays the biggest role\n",
    "\n",
    "What are these type of plots called?\n",
    "\n",
    "This will show fx if food has the biggest impact - like just follow food ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check what it has learned regarding sharing information between cells\n",
    "\n",
    "Some way of visualizing this??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize what it stores in the hidden channels \n",
    "\n",
    "Maybe show across all cells what they see, and see how this evolves and changes during testing\n",
    "\n",
    "Maybe also look at what effect the hidden channels have and what changes them - and if the model even uses them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How are any of these things different between the three models?\n",
    "\n",
    "Does this support the hypothesis, make intuitiv meaning or in other sense correlate with the fact that some are more local than others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look into the hidden parameters\n",
    "\n",
    "How are they used??\n",
    "\n",
    "Plot them\n",
    "\n",
    "When are each changed and what affec them\n",
    "\n",
    "How do they look over time?\n",
    "\n",
    "Are they exploding, vanishing or even being used?"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
