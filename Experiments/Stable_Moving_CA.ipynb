{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stable Moving CA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision \n",
    "from tqdm import tqdm\n",
    "\n",
    "import IPython\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "#device = torch.device('mps:0' if torch.backends.mps.is_available else 'cpu')\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available else 'cpu')\n",
    "#device = torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CA(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CA, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(2, 8, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(8, 8, 1, padding=0)\n",
    "        self.conv3 = nn.Conv2d(8, 2, 1, padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(x.shape)\n",
    "        z = self.conv1(x)\n",
    "        print(z.shape)\n",
    "        z = torch.relu(z)\n",
    "        print(z.shape)\n",
    "        z = self.conv2(z)\n",
    "        print(z.shape)\n",
    "        z = torch.relu(z)\n",
    "        print(z.shape)\n",
    "        z = self.conv3(z)\n",
    "        #z = torch.sigmoid(z)\n",
    "\n",
    "        #trying to ensure \n",
    "        #scale = torch.sum(x) / torch.sum(z)\n",
    "        #z = torch.mul(z, scale)\n",
    "\n",
    "        #trying to ensure the same amount of alive CAs\n",
    "        #alive_count = torch.count_nonzero(torch.where(z > 0.1, z, 0))\n",
    "        #return z, alive_count\n",
    "        print(z.shape)\n",
    "        return z\n",
    "\n",
    "    #add helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, state, iterations, optimizer, criterion, epochs=1):\n",
    "    #mat = torch.rand(32, 32, device=device)\n",
    "    mat = torch.zeros(32, 32, device=device)\n",
    "    mat2 = torch.rand(3,3, device=device)\n",
    "    mat[:3, :3] = mat2\n",
    "    mat[-3:, -3:] = mat2\n",
    "    #state = np.stack([1 - state, state])\n",
    "    #state = torch.stack([1 - state, state])\n",
    "    state = torch.stack([1 - mat, mat])\n",
    "    #state = torch.rand(2, 32, 32, device=device)\n",
    "    losses = np.zeros(iterations * epochs)\n",
    "    #for epoch in range(epochs):\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        #for i in tqdm(range(iterations)):\n",
    "        for i in range(iterations):\n",
    "            #input_alive_count = torch.count_nonzero(torch.where(state > 0.1, state, 0)).type(torch.float32)\n",
    "            #torch.where(x > 0 | x<0.1, x, y)\n",
    "            #kunne lave en tensor med count pÃ¥ mellem 0.0-0.1, 0.1-0.2, 0.2-0.3 ...\n",
    "            optimizer.zero_grad()\n",
    "            state_hat = state\n",
    "            for j in range(epochs):\n",
    "                #state_hat, alive_count = model(state_hat)\n",
    "                print(state_hat.shape)\n",
    "                state_hat = model(state_hat)\n",
    "                if j + 1 < epoch:\n",
    "                    loss = criterion(state_hat, state)\n",
    "                    loss.backward(retain_graph=True)\n",
    "\n",
    "            #scale = torch.sum(state) / torch.sum(state_hat)\n",
    "            loss = criterion(state_hat, state)\n",
    "            #loss.requires_grad = True\n",
    "            #loss2 = criterion(scale, torch.tensor([1.0], device=device))\n",
    "            #alive_count = alive_count.type(torch.float32)\n",
    "            #loss3 = criterion(alive_count, input_alive_count) * 0.000001\n",
    "            #loss = loss1 #+ loss2 #+ loss3\n",
    "            losses[epoch*iterations + i] = loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(loss)\n",
    "    return model, losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initial state\n",
    "#...\n",
    "glider = np.array([[0,1,0],\n",
    "                   [0,0,1],\n",
    "                   [1,1,1]])\n",
    "state = np.zeros((32, 32), dtype=np.float32)\n",
    "state[:3,:3] = glider\n",
    "state = np.stack([1 - state, state]) # why? - what does this do\n",
    "state = torch.from_numpy(state)\n",
    "state = state.to(device)\n",
    "\n",
    "model = CA().to(device)\n",
    "iterations = 400\n",
    "epochs = 20\n",
    "lr = 0.0001\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "#criterion = nn.MSELoss()\n",
    "criterion = nn.L1Loss()\n",
    "model, losses = train(model, state, iterations, optimizer, criterion, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'losses' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [14], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m#plot\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m plt\u001b[39m.\u001b[39mplot(losses)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'losses' is not defined"
     ]
    }
   ],
   "source": [
    "#plot\n",
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save progress\n",
    "torch.save(model.state_dict(), 'model1.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test - Animate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CA()\n",
    "model.load_state_dict(torch.load('model.pth'))\n",
    "model = model.to(device)\n",
    "#Setup\n",
    "glider = np.array([[0,1,0],\n",
    "                   [0,0,1],\n",
    "                   [1,1,1]])\n",
    "state = np.zeros((32, 32))\n",
    "state[:3,:3] = glider\n",
    "#state[0,0]= 1\n",
    "state = np.stack([1 - state, state])\n",
    "state = torch.from_numpy(state).float().unsqueeze(0).to(device)\n",
    "print(state.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test with random state\n",
    "mat = torch.rand(32, 32, device=device)\n",
    "state = torch.stack([1 - mat, mat]).unsqueeze(0)\n",
    "print(state.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#iterate\n",
    "@torch.no_grad()\n",
    "def animate(i):\n",
    "    global state\n",
    "    #state = torch.softmax(model(state), dim=1).to(device) #calculate new state\n",
    "    state = model(state) #calculate new state\n",
    "    mat.set_data(state.detach().cpu().numpy()[0,0]) #update the mat shown to reflect the new state\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "mat = ax.matshow(state.detach().cpu().numpy()[0,0], cmap=\"gray\") #show mat in fig\n",
    "\n",
    "IPython.display.HTML(animation.FuncAnimation(fig, animate, frames=1000, interval=10).to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state1 = state\n",
    "state1 = model(state1)\n",
    "plt.imshow(state1.reshape(2, 32,32).cpu().detach().numpy()[0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in model.parameters():\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hpc2",
   "language": "python",
   "name": "hpc2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "20afb3d869327389044feed7fefb9b458eb6296b59bc368887fba7799b57fd31"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
